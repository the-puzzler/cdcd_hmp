{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from helper_funcs import generate_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 6486\n",
      "Test size: 1622\n",
      "\n",
      "First few training samples:\n",
      "                                                            otu_arrays\n",
      "Unnamed: 0                                                            \n",
      "SRR044975.SRS011167  [30, 58, 82, 89, 93, 98, 99, 104, 117, 120, 12...\n",
      "SRR049604.SRS049164  [9, 10, 11, 14, 15, 16, 17, 20, 28, 30, 31, 32...\n",
      "SRR331714.SRS076947  [19, 30, 43, 58, 65, 70, 71, 74, 80, 90, 92, 9...\n",
      "SRR089999.SRS077685  [12, 14, 18, 20, 22, 38, 45, 67, 68, 76, 88, 1...\n",
      "SRR048091.SRS021563  [19, 30, 45, 52, 58, 60, 65, 70, 74, 80, 90, 9...\n",
      "\n",
      "Min array length: 3\n",
      "Max array length: 277\n",
      "Mean array length: 69.10\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "loaded_df = pd.read_hdf('./data/sample_otu_arrays.h5', key='df')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split indices into train/test\n",
    "train_idx, test_idx = train_test_split(loaded_df.index, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and test dataframes\n",
    "train_df = loaded_df.loc[train_idx]\n",
    "test_df = loaded_df.loc[test_idx]\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")\n",
    "print(\"\\nFirst few training samples:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# Let's also look at array lengths\n",
    "array_lengths = [len(x) for x in loaded_df['otu_arrays']]\n",
    "print(f\"\\nMin array length: {min(array_lengths)}\")\n",
    "print(f\"Max array length: {max(array_lengths)}\")\n",
    "print(f\"Mean array length: {np.mean(array_lengths):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch tokens shape: torch.Size([68, 277])\n",
      "Batch mask shape: torch.Size([68, 277])\n",
      "\n",
      "Vocabulary size: 519\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class OTUDataset(Dataset):\n",
    "   def __init__(self, df):\n",
    "       self.df = df\n",
    "       \n",
    "       # Find max sequence length for padding\n",
    "       self.max_len = max(len(x) for x in df['otu_arrays'])\n",
    "       \n",
    "   def __len__(self):\n",
    "       return len(self.df)\n",
    "   \n",
    "   def __getitem__(self, idx):\n",
    "       # Get array for this sample\n",
    "       array = self.df.iloc[idx]['otu_arrays']\n",
    "       \n",
    "       # Create padded tensor\n",
    "       padded = torch.zeros(self.max_len, dtype=torch.long)\n",
    "       padded[:len(array)] = torch.tensor(array)\n",
    "       \n",
    "       # Create mask (False where we have real tokens, True for padding)\n",
    "       mask = torch.zeros(self.max_len, dtype=torch.bool)\n",
    "       mask[len(array):] = True\n",
    "       \n",
    "       return padded, mask\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = OTUDataset(train_df)\n",
    "test_dataset = OTUDataset(test_df)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 68\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Verify shapes\n",
    "for tokens, mask in train_loader:\n",
    "   print(f\"Batch tokens shape: {tokens.shape}\")\n",
    "   print(f\"Batch mask shape: {mask.shape}\")\n",
    "\n",
    "   break\n",
    "\n",
    "# Get vocab size (maximum token ID + 1 for padding)\n",
    "vocab_size = max(max(x) for x in loaded_df['otu_arrays']) + 1\n",
    "print(f\"\\nVocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper_funcs' from '/mnt/mnemo9/mpelus/matlas/cdcd_multi_train/cdcd_hmp/helper_funcs.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model_arch\n",
    "import helper_funcs\n",
    "import importlib\n",
    "from model_arch import CategoricalScoreDiffusion\n",
    "from helper_funcs import generate_sequences\n",
    "importlib.reload(model_arch)\n",
    "importlib.reload(helper_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainingMetrics:\n",
    "    def __init__(self):\n",
    "        self.best_val_loss = float('inf')\n",
    "\n",
    "        \n",
    "    def update_best_metrics(self, val_loss):\n",
    "        improved = False\n",
    "        if val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            improved = True\n",
    "        return improved\n",
    "\n",
    "def train_step(model, tokens, mask, optimizer, device):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Sample time using warping\n",
    "    t = model.sample_time(tokens.shape[0], tokens.device)\n",
    "\n",
    "    # Get clean embeddings\n",
    "    x0 = model.embedding(tokens)\n",
    "  \n",
    "    \n",
    "    # Add noise\n",
    "    noise = model.get_noise(x0, t)\n",
    "\n",
    "    xt = x0 + noise\n",
    "\n",
    "    \n",
    "    # Get model predictions\n",
    "    logits = model(xt, mask, t)\n",
    "\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = F.cross_entropy(\n",
    "        logits.view(-1, logits.size(-1)),\n",
    "        tokens.view(-1),\n",
    "        ignore_index=0\n",
    "    )\n",
    "\n",
    "    if not torch.isnan(loss):\n",
    "        model.update_time_warping(t, loss.detach())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "def validation_step(model, tokens, mask, device):\n",
    "    # Sample time using warping\n",
    "    t = model.sample_time(tokens.shape[0], tokens.device)\n",
    "    \n",
    "    # Get clean embeddings\n",
    "    x0 = model.embedding(tokens)\n",
    "    \n",
    "    # Add noise according to N(0, σt²)\n",
    "    noise = model.get_noise(x0, t)\n",
    "    xt = x0 + noise\n",
    "    \n",
    "    # Get model predictions\n",
    "    logits = model(xt, mask, t)\n",
    "    \n",
    "    # Compute cross-entropy loss with padding handling\n",
    "    loss = F.cross_entropy(\n",
    "        logits.view(-1, logits.size(-1)),\n",
    "        tokens.view(-1),\n",
    "        ignore_index=0  # Assuming 0 is padding token\n",
    "    )\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "def save_checkpoint(model, optimizer, scheduler, epoch, train_loss, val_loss):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        \n",
    "    }\n",
    "    torch.save(checkpoint, 'best_model.pt')\n",
    "\n",
    "def log_metrics(metrics_dict, step_type='batch'):\n",
    "    wandb.log(metrics_dict)\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_bar = tqdm(train_loader, desc=f'Training Epoch {epoch}')\n",
    "    \n",
    "    for batch_idx, (tokens, mask) in enumerate(train_bar):\n",
    "        tokens = tokens.to(device)\n",
    "        mask = mask.to(device)\n",
    "        \n",
    "        loss = train_step(model, tokens, mask, optimizer, device)\n",
    "        train_loss += loss\n",
    "        \n",
    "        train_bar.set_postfix({'loss': f'{loss:.4f}'})\n",
    "        log_metrics({\n",
    "            'train/batch_loss': loss,\n",
    "            'train/learning_rate': optimizer.param_groups[0]['lr'],\n",
    "            'epoch': epoch,\n",
    "            'batch': batch_idx\n",
    "        })\n",
    "    \n",
    "    return train_loss / len(train_loader)\n",
    "\n",
    "def validate_epoch(model, test_loader, device, epoch):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_bar = tqdm(test_loader, desc=f'Validation Epoch {epoch}')\n",
    "    \n",
    "    # Collect real sequences\n",
    "    real_sequences = []\n",
    "    with torch.no_grad():\n",
    "        for tokens, mask in val_bar:\n",
    "            tokens = tokens.to(device)\n",
    "            mask = mask.to(device)\n",
    "            \n",
    "            loss = validation_step(model, tokens, mask, device)\n",
    "            val_loss += loss\n",
    "            val_bar.set_postfix({'loss': f'{loss:.4f}'})\n",
    "            \n",
    "            real_sequences.extend([seq[seq != 0].cpu().numpy() for seq in tokens])\n",
    "\n",
    "    \n",
    "    return val_loss / len(test_loader)\n",
    "\n",
    "\n",
    "\n",
    "def train_and_validate(model, train_loader, test_loader, optimizer, num_epochs, device, use_lr_scheduling=True):\n",
    "    metrics = TrainingMetrics()\n",
    "    \n",
    "    scheduler = None\n",
    "    if use_lr_scheduling:\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', patience=3, factor=0.5, verbose=True\n",
    "        )\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        avg_train_loss = train_epoch(model, train_loader, optimizer, device, epoch)\n",
    "        log_metrics({'train/epoch_loss': avg_train_loss, 'epoch': epoch})\n",
    "         \n",
    "        # Validation phase (every 5 epochs)\n",
    "        if epoch % 1 == 0:\n",
    "            avg_val_loss = validate_epoch(model, test_loader, device, epoch)\n",
    "            \n",
    "            log_metrics({\n",
    "                'val/epoch_loss': avg_val_loss,\n",
    "                'epoch': epoch\n",
    "            })\n",
    "            \n",
    "            print(f'\\nEpoch {epoch}:')\n",
    "            print(f'Average Train Loss: {avg_train_loss:.4f}')\n",
    "            print(f'Average Val Loss: {avg_val_loss:.4f}')\n",
    "         \n",
    "            \n",
    "            if scheduler:\n",
    "                scheduler.step(avg_val_loss)\n",
    "            \n",
    "            if metrics.update_best_metrics(avg_val_loss):\n",
    "                save_checkpoint(model, optimizer, scheduler, epoch, avg_train_loss, avg_val_loss)\n",
    "                log_metrics({\n",
    "                    'best_model/val_loss': avg_val_loss,\n",
    "                    'best_model/train_loss': avg_train_loss,\n",
    "                    'best_model/epoch': epoch\n",
    "                })\n",
    "        else:\n",
    "            print(f'\\nEpoch {epoch}: Average Train Loss: {avg_train_loss:.4f}\\n')\n",
    "\n",
    "\n",
    "def train_step(model, tokens, mask, optimizer, device):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    t = model.sample_time(tokens.shape[0], tokens.device)\n",
    "    x0 = model.embedding(tokens)\n",
    "    noise = model.get_noise(x0, t)\n",
    "    xt = x0 + noise\n",
    "    logits = model(xt, mask, t)\n",
    "    \n",
    "    loss = F.cross_entropy(\n",
    "        logits.view(-1, logits.size(-1)),\n",
    "        tokens.view(-1),\n",
    "        ignore_index=0\n",
    "    )\n",
    "\n",
    "    if not torch.isnan(loss):\n",
    "        # Just collect statistics instead of updating\n",
    "        model.collect_time_statistics(t, loss.detach())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    num_batches = len(train_loader)\n",
    "    \n",
    "    # Reset statistics at start of epoch\n",
    "    model.epoch_loss_history.zero_()\n",
    "    model.epoch_count_history.zero_()\n",
    "    \n",
    "    train_bar = tqdm(train_loader, desc=f'Training Epoch {epoch}')\n",
    "    \n",
    "    for batch_idx, (tokens, mask) in enumerate(train_bar):\n",
    "        tokens = tokens.to(device)\n",
    "        mask = mask.to(device)\n",
    "        \n",
    "        loss = train_step(model, tokens, mask, optimizer, device)\n",
    "        train_loss += loss\n",
    "        train_bar.set_postfix({'loss': f'{loss:.4f}'})\n",
    "        \n",
    "        log_metrics({\n",
    "            'train/batch_loss': loss,\n",
    "            'train/learning_rate': optimizer.param_groups[0]['lr'],\n",
    "            'epoch': epoch,\n",
    "            'batch': batch_idx\n",
    "        })\n",
    "    \n",
    "    # Update time warping at end of epoch\n",
    "    model.update_time_warping_epoch()\n",
    "    \n",
    "    return train_loss / num_batches\n",
    "\n",
    "def train_step(model, tokens, mask, optimizer, device):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    t = model.sample_time(tokens.shape[0], tokens.device)\n",
    "    x0 = model.embedding(tokens)\n",
    "    noise = model.get_noise(x0, t)\n",
    "    xt = x0 + noise\n",
    "    logits = model(xt, mask, t)\n",
    "    \n",
    "    loss = F.cross_entropy(\n",
    "        logits.view(-1, logits.size(-1)),\n",
    "        tokens.view(-1),\n",
    "        ignore_index=0\n",
    "    )\n",
    "\n",
    "    if not torch.isnan(loss):\n",
    "        # Update time warping statistics and weights immediately\n",
    "        model.collect_time_statistics(t, loss.detach())\n",
    "        model.update_time_warping_batch()  # New method we'll add\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    num_batches = len(train_loader)\n",
    "    \n",
    "    train_bar = tqdm(train_loader, desc=f'Training Epoch {epoch}')\n",
    "    \n",
    "    for batch_idx, (tokens, mask) in enumerate(train_bar):\n",
    "        tokens = tokens.to(device)\n",
    "        mask = mask.to(device)\n",
    "        \n",
    "        loss = train_step(model, tokens, mask, optimizer, device)\n",
    "        train_loss += loss\n",
    "        train_bar.set_postfix({'loss': f'{loss:.4f}'})\n",
    "        \n",
    "        log_metrics({\n",
    "            'train/batch_loss': loss,\n",
    "            'train/learning_rate': optimizer.param_groups[0]['lr'],\n",
    "            'epoch': epoch,\n",
    "            'batch': batch_idx\n",
    "        })\n",
    "    \n",
    "    return train_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "embed_dim =16 #8 \n",
    "num_layers = 5 #5\n",
    "num_heads = 4\n",
    "dim_feedforward = 32 #32\n",
    "num_fourier_features = 8# going from 4 to 8 destabilised the batch loss but seems o have resulted in a faster convergence and lower\n",
    "model = CategoricalScoreDiffusion(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    num_layers=num_layers,\n",
    "    num_heads=num_heads,\n",
    "    dim_feedforward=dim_feedforward,\n",
    "    num_fourier_features=num_fourier_features\n",
    "    \n",
    ")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Move model to device\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatteopeluso1922\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/mnemo9/mpelus/matlas/cdcd_multi_train/cdcd_hmp/wandb/run-20250118_172209-32ett199</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matteopeluso1922/diffusion-hmp/runs/32ett199' target=\"_blank\">devout-night-74</a></strong> to <a href='https://wandb.ai/matteopeluso1922/diffusion-hmp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matteopeluso1922/diffusion-hmp' target=\"_blank\">https://wandb.ai/matteopeluso1922/diffusion-hmp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matteopeluso1922/diffusion-hmp/runs/32ett199' target=\"_blank\">https://wandb.ai/matteopeluso1922/diffusion-hmp/runs/32ett199</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/matteopeluso1922/diffusion-hmp/runs/32ett199?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fd89196f7d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "num_epochs = 200\n",
    "learning_rate = 1e-3\n",
    "\n",
    "wandb.finish()\n",
    "wandb.init(\n",
    "    project=\"diffusion-hmp\",\n",
    "    config={\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"architecture\": \"restart\",\n",
    "        \"dataset\": \"hmp\",\n",
    "        \"epochs\": num_epochs,\n",
    "        \"embed_dim\": embed_dim,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"num_heads\": num_heads,\n",
    "        \"dim_feedforward\": dim_feedforward,\n",
    "        \"vocab_size\": vocab_size,\n",
    "        \"num_fourier_features\":num_fourier_features\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/mnemo7/mpelus/miniconda3/envs/matlas/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Training Epoch 0: 100%|██████████| 96/96 [00:04<00:00, 23.65it/s, loss=5.0822]\n",
      "Validation Epoch 0:   0%|          | 0/24 [00:00<?, ?it/s]/mnt/mnemo7/mpelus/miniconda3/envs/matlas/lib/python3.12/site-packages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /opt/conda/conda-bld/pytorch_1729647378361/work/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "Validation Epoch 0: 100%|██████████| 24/24 [00:03<00:00,  7.34it/s, loss=5.0721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:\n",
      "Average Train Loss: 5.3628\n",
      "Average Val Loss: 5.0480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 96/96 [00:04<00:00, 22.74it/s, loss=4.7633]\n",
      "Validation Epoch 1: 100%|██████████| 24/24 [00:02<00:00, 11.03it/s, loss=4.6936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:\n",
      "Average Train Loss: 4.8146\n",
      "Average Val Loss: 4.7015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 96/96 [00:03<00:00, 24.77it/s, loss=4.3543]\n",
      "Validation Epoch 2: 100%|██████████| 24/24 [00:03<00:00,  6.98it/s, loss=4.5947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2:\n",
      "Average Train Loss: 4.6219\n",
      "Average Val Loss: 4.5783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 96/96 [00:04<00:00, 23.85it/s, loss=4.6707]\n",
      "Validation Epoch 3: 100%|██████████| 24/24 [00:01<00:00, 14.79it/s, loss=4.4326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3:\n",
      "Average Train Loss: 4.5405\n",
      "Average Val Loss: 4.4808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 96/96 [00:04<00:00, 22.88it/s, loss=4.5727]\n",
      "Validation Epoch 4: 100%|██████████| 24/24 [00:03<00:00,  7.20it/s, loss=4.6450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4:\n",
      "Average Train Loss: 4.4549\n",
      "Average Val Loss: 4.4685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 96/96 [00:03<00:00, 29.45it/s, loss=4.3374]\n",
      "Validation Epoch 5: 100%|██████████| 24/24 [00:03<00:00,  7.32it/s, loss=4.3760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5:\n",
      "Average Train Loss: 4.4166\n",
      "Average Val Loss: 4.3824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 96/96 [00:04<00:00, 22.78it/s, loss=4.4902]\n",
      "Validation Epoch 6: 100%|██████████| 24/24 [00:02<00:00, 11.42it/s, loss=4.2369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6:\n",
      "Average Train Loss: 4.3903\n",
      "Average Val Loss: 4.4092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 96/96 [00:03<00:00, 25.45it/s, loss=4.7689]\n",
      "Validation Epoch 7: 100%|██████████| 24/24 [00:03<00:00,  7.17it/s, loss=4.4086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7:\n",
      "Average Train Loss: 4.3611\n",
      "Average Val Loss: 4.3407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 96/96 [00:04<00:00, 22.98it/s, loss=4.5321]\n",
      "Validation Epoch 8: 100%|██████████| 24/24 [00:01<00:00, 20.57it/s, loss=4.3295]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8:\n",
      "Average Train Loss: 4.3306\n",
      "Average Val Loss: 4.2751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 96/96 [00:04<00:00, 22.83it/s, loss=4.0986]\n",
      "Validation Epoch 9: 100%|██████████| 24/24 [00:03<00:00,  6.88it/s, loss=4.5237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9:\n",
      "Average Train Loss: 4.2604\n",
      "Average Val Loss: 4.2434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 96/96 [00:03<00:00, 28.41it/s, loss=4.1995]\n",
      "Validation Epoch 10: 100%|██████████| 24/24 [00:00<00:00, 55.88it/s, loss=4.0865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10:\n",
      "Average Train Loss: 4.2637\n",
      "Average Val Loss: 4.1997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|██████████| 96/96 [00:02<00:00, 42.27it/s, loss=4.0443]\n",
      "Validation Epoch 11: 100%|██████████| 24/24 [00:00<00:00, 66.75it/s, loss=4.1812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11:\n",
      "Average Train Loss: 4.2535\n",
      "Average Val Loss: 4.1553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|██████████| 96/96 [00:02<00:00, 41.43it/s, loss=4.4283]\n",
      "Validation Epoch 12: 100%|██████████| 24/24 [00:02<00:00,  9.02it/s, loss=4.1299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12:\n",
      "Average Train Loss: 4.2013\n",
      "Average Val Loss: 4.1791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|██████████| 96/96 [00:04<00:00, 23.55it/s, loss=3.7490]\n",
      "Validation Epoch 13: 100%|██████████| 24/24 [00:03<00:00,  7.51it/s, loss=4.4620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13:\n",
      "Average Train Loss: 4.2017\n",
      "Average Val Loss: 4.1311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|██████████| 96/96 [00:03<00:00, 31.38it/s, loss=3.7119]\n",
      "Validation Epoch 14: 100%|██████████| 24/24 [00:02<00:00,  8.36it/s, loss=3.7523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14:\n",
      "Average Train Loss: 4.1292\n",
      "Average Val Loss: 4.0650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|██████████| 96/96 [00:04<00:00, 22.89it/s, loss=3.9251]\n",
      "Validation Epoch 15: 100%|██████████| 24/24 [00:03<00:00,  7.54it/s, loss=4.3253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15:\n",
      "Average Train Loss: 4.1468\n",
      "Average Val Loss: 4.1704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|██████████| 96/96 [00:02<00:00, 32.14it/s, loss=4.1871]\n",
      "Validation Epoch 16: 100%|██████████| 24/24 [00:03<00:00,  7.84it/s, loss=4.1745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16:\n",
      "Average Train Loss: 4.1092\n",
      "Average Val Loss: 4.0847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|██████████| 96/96 [00:04<00:00, 22.95it/s, loss=4.2570]\n",
      "Validation Epoch 17: 100%|██████████| 24/24 [00:03<00:00,  7.32it/s, loss=3.8277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17:\n",
      "Average Train Loss: 4.0963\n",
      "Average Val Loss: 4.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|██████████| 96/96 [00:02<00:00, 34.09it/s, loss=3.8582]\n",
      "Validation Epoch 18: 100%|██████████| 24/24 [00:03<00:00,  7.33it/s, loss=4.1435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18:\n",
      "Average Train Loss: 4.0459\n",
      "Average Val Loss: 4.1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|██████████| 96/96 [00:04<00:00, 23.16it/s, loss=4.0876]\n",
      "Validation Epoch 19: 100%|██████████| 24/24 [00:03<00:00,  7.49it/s, loss=3.9804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19:\n",
      "Average Train Loss: 4.0808\n",
      "Average Val Loss: 4.0640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|██████████| 96/96 [00:02<00:00, 33.45it/s, loss=3.8995]\n",
      "Validation Epoch 20: 100%|██████████| 24/24 [00:03<00:00,  7.74it/s, loss=4.1042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20:\n",
      "Average Train Loss: 4.0947\n",
      "Average Val Loss: 4.0679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21: 100%|██████████| 96/96 [00:04<00:00, 22.93it/s, loss=3.9190]\n",
      "Validation Epoch 21: 100%|██████████| 24/24 [00:03<00:00,  7.88it/s, loss=3.8125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21:\n",
      "Average Train Loss: 4.0521\n",
      "Average Val Loss: 3.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22: 100%|██████████| 96/96 [00:03<00:00, 30.94it/s, loss=4.0073]\n",
      "Validation Epoch 22: 100%|██████████| 24/24 [00:03<00:00,  7.22it/s, loss=4.0241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22:\n",
      "Average Train Loss: 4.0082\n",
      "Average Val Loss: 4.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23: 100%|██████████| 96/96 [00:04<00:00, 22.70it/s, loss=4.1507]\n",
      "Validation Epoch 23: 100%|██████████| 24/24 [00:02<00:00,  9.04it/s, loss=4.2321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23:\n",
      "Average Train Loss: 4.0233\n",
      "Average Val Loss: 4.0313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24: 100%|██████████| 96/96 [00:03<00:00, 29.16it/s, loss=4.2742]\n",
      "Validation Epoch 24: 100%|██████████| 24/24 [00:03<00:00,  7.27it/s, loss=3.6869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24:\n",
      "Average Train Loss: 4.0581\n",
      "Average Val Loss: 3.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25: 100%|██████████| 96/96 [00:04<00:00, 22.68it/s, loss=3.7281]\n",
      "Validation Epoch 25: 100%|██████████| 24/24 [00:02<00:00,  9.86it/s, loss=4.2957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25:\n",
      "Average Train Loss: 3.8819\n",
      "Average Val Loss: 3.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26: 100%|██████████| 96/96 [00:03<00:00, 27.94it/s, loss=3.8483]\n",
      "Validation Epoch 26: 100%|██████████| 24/24 [00:03<00:00,  7.17it/s, loss=4.0238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26:\n",
      "Average Train Loss: 3.8934\n",
      "Average Val Loss: 3.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27: 100%|██████████| 96/96 [00:04<00:00, 22.67it/s, loss=4.1040]\n",
      "Validation Epoch 27: 100%|██████████| 24/24 [00:02<00:00, 10.76it/s, loss=4.0548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27:\n",
      "Average Train Loss: 3.8849\n",
      "Average Val Loss: 3.8685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 28: 100%|██████████| 96/96 [00:03<00:00, 26.51it/s, loss=4.1792]\n",
      "Validation Epoch 28: 100%|██████████| 24/24 [00:03<00:00,  7.27it/s, loss=3.9977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28:\n",
      "Average Train Loss: 3.8928\n",
      "Average Val Loss: 3.8521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 29: 100%|██████████| 96/96 [00:04<00:00, 23.03it/s, loss=4.1528]\n",
      "Validation Epoch 29: 100%|██████████| 24/24 [00:02<00:00, 11.49it/s, loss=3.4880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29:\n",
      "Average Train Loss: 3.8607\n",
      "Average Val Loss: 3.8140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 30: 100%|██████████| 96/96 [00:03<00:00, 25.85it/s, loss=3.4933]\n",
      "Validation Epoch 30: 100%|██████████| 24/24 [00:03<00:00,  7.25it/s, loss=3.7965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30:\n",
      "Average Train Loss: 3.8828\n",
      "Average Val Loss: 3.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 31: 100%|██████████| 96/96 [00:04<00:00, 22.94it/s, loss=3.7610]\n",
      "Validation Epoch 31: 100%|██████████| 24/24 [00:01<00:00, 12.09it/s, loss=4.1890]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31:\n",
      "Average Train Loss: 3.8967\n",
      "Average Val Loss: 3.9032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 32: 100%|██████████| 96/96 [00:02<00:00, 40.53it/s, loss=3.7149]\n",
      "Validation Epoch 32: 100%|██████████| 24/24 [00:00<00:00, 66.94it/s, loss=4.1345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32:\n",
      "Average Train Loss: 3.8704\n",
      "Average Val Loss: 3.8540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 33: 100%|██████████| 96/96 [00:02<00:00, 42.39it/s, loss=3.9422]\n",
      "Validation Epoch 33: 100%|██████████| 24/24 [00:00<00:00, 66.53it/s, loss=4.1170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33:\n",
      "Average Train Loss: 3.8443\n",
      "Average Val Loss: 3.8959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 34: 100%|██████████| 96/96 [00:03<00:00, 31.74it/s, loss=4.4045]\n",
      "Validation Epoch 34: 100%|██████████| 24/24 [00:02<00:00, 11.78it/s, loss=3.6694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34:\n",
      "Average Train Loss: 3.8608\n",
      "Average Val Loss: 3.8672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 35: 100%|██████████| 96/96 [00:03<00:00, 30.16it/s, loss=3.8513]\n",
      "Validation Epoch 35: 100%|██████████| 24/24 [00:02<00:00, 11.65it/s, loss=3.5754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35:\n",
      "Average Train Loss: 3.8507\n",
      "Average Val Loss: 3.8528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 36: 100%|██████████| 96/96 [00:03<00:00, 28.81it/s, loss=4.4768]\n",
      "Validation Epoch 36: 100%|██████████| 24/24 [00:02<00:00, 11.76it/s, loss=3.6812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36:\n",
      "Average Train Loss: 3.8710\n",
      "Average Val Loss: 3.8082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 37: 100%|██████████| 96/96 [00:03<00:00, 26.72it/s, loss=3.9573]\n",
      "Validation Epoch 37: 100%|██████████| 24/24 [00:01<00:00, 15.64it/s, loss=3.6087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37:\n",
      "Average Train Loss: 3.8520\n",
      "Average Val Loss: 3.8409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 38: 100%|██████████| 96/96 [00:03<00:00, 25.43it/s, loss=4.0224]\n",
      "Validation Epoch 38: 100%|██████████| 24/24 [00:01<00:00, 20.92it/s, loss=4.0125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38:\n",
      "Average Train Loss: 3.8409\n",
      "Average Val Loss: 3.8706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 39: 100%|██████████| 96/96 [00:03<00:00, 25.40it/s, loss=3.9551]\n",
      "Validation Epoch 39: 100%|██████████| 24/24 [00:01<00:00, 13.49it/s, loss=3.7907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39:\n",
      "Average Train Loss: 3.8261\n",
      "Average Val Loss: 3.8130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 40: 100%|██████████| 96/96 [00:03<00:00, 27.64it/s, loss=3.4866]\n",
      "Validation Epoch 40: 100%|██████████| 24/24 [00:02<00:00, 10.87it/s, loss=3.6550]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40:\n",
      "Average Train Loss: 3.7569\n",
      "Average Val Loss: 3.7256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 41: 100%|██████████| 96/96 [00:03<00:00, 28.94it/s, loss=3.6292]\n",
      "Validation Epoch 41: 100%|██████████| 24/24 [00:02<00:00, 10.12it/s, loss=3.8004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41:\n",
      "Average Train Loss: 3.6586\n",
      "Average Val Loss: 3.6599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42: 100%|██████████| 96/96 [00:03<00:00, 29.74it/s, loss=3.3096]\n",
      "Validation Epoch 42: 100%|██████████| 24/24 [00:02<00:00,  9.90it/s, loss=3.5164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42:\n",
      "Average Train Loss: 3.6408\n",
      "Average Val Loss: 3.6872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 43: 100%|██████████| 96/96 [00:03<00:00, 29.72it/s, loss=3.1166]\n",
      "Validation Epoch 43: 100%|██████████| 24/24 [00:02<00:00, 10.16it/s, loss=3.6759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43:\n",
      "Average Train Loss: 3.6810\n",
      "Average Val Loss: 3.6771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 44: 100%|██████████| 96/96 [00:03<00:00, 29.69it/s, loss=3.8997]\n",
      "Validation Epoch 44: 100%|██████████| 24/24 [00:02<00:00, 10.27it/s, loss=3.8448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44:\n",
      "Average Train Loss: 3.6713\n",
      "Average Val Loss: 3.6470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 45: 100%|██████████| 96/96 [00:02<00:00, 33.67it/s, loss=3.9613]\n",
      "Validation Epoch 45: 100%|██████████| 24/24 [00:00<00:00, 66.24it/s, loss=4.0208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45:\n",
      "Average Train Loss: 3.6443\n",
      "Average Val Loss: 3.7053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 46: 100%|██████████| 96/96 [00:02<00:00, 42.28it/s, loss=3.6722]\n",
      "Validation Epoch 46: 100%|██████████| 24/24 [00:00<00:00, 66.02it/s, loss=3.7349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46:\n",
      "Average Train Loss: 3.6547\n",
      "Average Val Loss: 3.6355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 47: 100%|██████████| 96/96 [00:02<00:00, 41.16it/s, loss=3.5672]\n",
      "Validation Epoch 47: 100%|██████████| 24/24 [00:03<00:00,  6.23it/s, loss=3.7636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47:\n",
      "Average Train Loss: 3.6721\n",
      "Average Val Loss: 3.6272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 48: 100%|██████████| 96/96 [00:04<00:00, 21.81it/s, loss=3.1180]\n",
      "Validation Epoch 48: 100%|██████████| 24/24 [00:04<00:00,  5.96it/s, loss=3.6748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48:\n",
      "Average Train Loss: 3.6655\n",
      "Average Val Loss: 3.6268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 49: 100%|██████████| 96/96 [00:04<00:00, 23.14it/s, loss=3.6092]\n",
      "Validation Epoch 49: 100%|██████████| 24/24 [00:02<00:00, 10.15it/s, loss=3.3725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49:\n",
      "Average Train Loss: 3.6173\n",
      "Average Val Loss: 3.6520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 50: 100%|██████████| 96/96 [00:04<00:00, 21.84it/s, loss=3.4467]\n",
      "Validation Epoch 50: 100%|██████████| 24/24 [00:04<00:00,  5.47it/s, loss=3.7142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50:\n",
      "Average Train Loss: 3.6491\n",
      "Average Val Loss: 3.6714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 51: 100%|██████████| 96/96 [00:04<00:00, 21.84it/s, loss=3.3211]\n",
      "Validation Epoch 51: 100%|██████████| 24/24 [00:02<00:00, 11.24it/s, loss=3.7119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 51:\n",
      "Average Train Loss: 3.6625\n",
      "Average Val Loss: 3.6634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 52: 100%|██████████| 96/96 [00:04<00:00, 22.58it/s, loss=3.9297]\n",
      "Validation Epoch 52: 100%|██████████| 24/24 [00:04<00:00,  5.53it/s, loss=3.6132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 52:\n",
      "Average Train Loss: 3.6562\n",
      "Average Val Loss: 3.7064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 53: 100%|██████████| 96/96 [00:04<00:00, 21.57it/s, loss=3.8765]\n",
      "Validation Epoch 53: 100%|██████████| 24/24 [00:03<00:00,  6.69it/s, loss=3.8135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 53:\n",
      "Average Train Loss: 3.6561\n",
      "Average Val Loss: 3.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 54: 100%|██████████| 96/96 [00:03<00:00, 24.76it/s, loss=3.9796]\n",
      "Validation Epoch 54: 100%|██████████| 24/24 [00:04<00:00,  5.38it/s, loss=3.7481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54:\n",
      "Average Train Loss: 3.6930\n",
      "Average Val Loss: 3.6819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 55: 100%|██████████| 96/96 [00:04<00:00, 21.65it/s, loss=3.4034]\n",
      "Validation Epoch 55: 100%|██████████| 24/24 [00:04<00:00,  5.89it/s, loss=3.3982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 55:\n",
      "Average Train Loss: 3.6628\n",
      "Average Val Loss: 3.6217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 56: 100%|██████████| 96/96 [00:03<00:00, 25.30it/s, loss=3.5816]\n",
      "Validation Epoch 56: 100%|██████████| 24/24 [00:04<00:00,  5.39it/s, loss=3.6161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 56:\n",
      "Average Train Loss: 3.6477\n",
      "Average Val Loss: 3.6471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 57: 100%|██████████| 96/96 [00:04<00:00, 21.77it/s, loss=3.8095]\n",
      "Validation Epoch 57: 100%|██████████| 24/24 [00:04<00:00,  5.64it/s, loss=3.4115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 57:\n",
      "Average Train Loss: 3.6700\n",
      "Average Val Loss: 3.5606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 58: 100%|██████████| 96/96 [00:03<00:00, 25.56it/s, loss=3.2341]\n",
      "Validation Epoch 58: 100%|██████████| 24/24 [00:04<00:00,  5.41it/s, loss=3.4315]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58:\n",
      "Average Train Loss: 3.6275\n",
      "Average Val Loss: 3.6399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 59: 100%|██████████| 96/96 [00:04<00:00, 21.75it/s, loss=3.5585]\n",
      "Validation Epoch 59: 100%|██████████| 24/24 [00:04<00:00,  5.54it/s, loss=3.7879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 59:\n",
      "Average Train Loss: 3.6402\n",
      "Average Val Loss: 3.6656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 60: 100%|██████████| 96/96 [00:03<00:00, 26.07it/s, loss=4.1770]\n",
      "Validation Epoch 60: 100%|██████████| 24/24 [00:04<00:00,  5.41it/s, loss=3.6632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60:\n",
      "Average Train Loss: 3.6505\n",
      "Average Val Loss: 3.5820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 61: 100%|██████████| 96/96 [00:04<00:00, 21.82it/s, loss=3.8978]\n",
      "Validation Epoch 61: 100%|██████████| 24/24 [00:04<00:00,  5.48it/s, loss=3.5783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 61:\n",
      "Average Train Loss: 3.6565\n",
      "Average Val Loss: 3.6426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 62: 100%|██████████| 96/96 [00:03<00:00, 25.98it/s, loss=4.1863]\n",
      "Validation Epoch 62: 100%|██████████| 24/24 [00:04<00:00,  5.41it/s, loss=3.5958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 62:\n",
      "Average Train Loss: 3.6175\n",
      "Average Val Loss: 3.6801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 63: 100%|██████████| 96/96 [00:04<00:00, 20.85it/s, loss=3.5726]\n",
      "Validation Epoch 63: 100%|██████████| 24/24 [00:04<00:00,  5.55it/s, loss=3.3395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 63:\n",
      "Average Train Loss: 3.6423\n",
      "Average Val Loss: 3.6508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 64: 100%|██████████| 96/96 [00:03<00:00, 25.93it/s, loss=3.7585]\n",
      "Validation Epoch 64: 100%|██████████| 24/24 [00:04<00:00,  5.47it/s, loss=3.4816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 64:\n",
      "Average Train Loss: 3.6120\n",
      "Average Val Loss: 3.6099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 65: 100%|██████████| 96/96 [00:04<00:00, 21.76it/s, loss=3.8225]\n",
      "Validation Epoch 65: 100%|██████████| 24/24 [00:04<00:00,  5.41it/s, loss=3.5347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 65:\n",
      "Average Train Loss: 3.6645\n",
      "Average Val Loss: 3.7330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 66: 100%|██████████| 96/96 [00:03<00:00, 26.06it/s, loss=3.8506]\n",
      "Validation Epoch 66: 100%|██████████| 24/24 [00:04<00:00,  5.39it/s, loss=3.7869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 66:\n",
      "Average Train Loss: 3.6591\n",
      "Average Val Loss: 3.6405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 67: 100%|██████████| 96/96 [00:04<00:00, 21.75it/s, loss=4.1466]\n",
      "Validation Epoch 67: 100%|██████████| 24/24 [00:04<00:00,  5.42it/s, loss=3.7548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 67:\n",
      "Average Train Loss: 3.6655\n",
      "Average Val Loss: 3.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 68: 100%|██████████| 96/96 [00:02<00:00, 34.79it/s, loss=3.3387]\n",
      "Validation Epoch 68: 100%|██████████| 24/24 [00:00<00:00, 65.57it/s, loss=3.5110]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 68:\n",
      "Average Train Loss: 3.6362\n",
      "Average Val Loss: 3.6729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 69: 100%|██████████| 96/96 [00:02<00:00, 42.18it/s, loss=3.4158]\n",
      "Validation Epoch 69: 100%|██████████| 24/24 [00:00<00:00, 67.03it/s, loss=3.7942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 69:\n",
      "Average Train Loss: 3.6625\n",
      "Average Val Loss: 3.6322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 70: 100%|██████████| 96/96 [00:02<00:00, 42.27it/s, loss=3.3033]\n",
      "Validation Epoch 70: 100%|██████████| 24/24 [00:00<00:00, 66.39it/s, loss=3.9910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70:\n",
      "Average Train Loss: 3.6350\n",
      "Average Val Loss: 3.6553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 71: 100%|██████████| 96/96 [00:02<00:00, 39.18it/s, loss=3.9266]\n",
      "Validation Epoch 71: 100%|██████████| 24/24 [00:00<00:00, 29.92it/s, loss=3.3124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 71:\n",
      "Average Train Loss: 3.6417\n",
      "Average Val Loss: 3.6575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 72: 100%|██████████| 96/96 [00:03<00:00, 31.95it/s, loss=3.7318]\n",
      "Validation Epoch 72: 100%|██████████| 24/24 [00:00<00:00, 27.97it/s, loss=3.7582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 72:\n",
      "Average Train Loss: 3.6379\n",
      "Average Val Loss: 3.6815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 73: 100%|██████████| 96/96 [00:02<00:00, 32.20it/s, loss=3.8657]\n",
      "Validation Epoch 73: 100%|██████████| 24/24 [00:00<00:00, 27.86it/s, loss=3.7060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 73:\n",
      "Average Train Loss: 3.6625\n",
      "Average Val Loss: 3.6187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 74: 100%|██████████| 96/96 [00:03<00:00, 31.97it/s, loss=3.5702]\n",
      "Validation Epoch 74: 100%|██████████| 24/24 [00:00<00:00, 28.80it/s, loss=3.9392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 74:\n",
      "Average Train Loss: 3.6417\n",
      "Average Val Loss: 3.6732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 75: 100%|██████████| 96/96 [00:02<00:00, 34.55it/s, loss=3.6868]\n",
      "Validation Epoch 75: 100%|██████████| 24/24 [00:00<00:00, 27.39it/s, loss=3.6906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 75:\n",
      "Average Train Loss: 3.6156\n",
      "Average Val Loss: 3.6161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 76: 100%|██████████| 96/96 [00:02<00:00, 32.28it/s, loss=3.6074]\n",
      "Validation Epoch 76: 100%|██████████| 24/24 [00:00<00:00, 27.94it/s, loss=3.8133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76:\n",
      "Average Train Loss: 3.6466\n",
      "Average Val Loss: 3.6335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 77: 100%|██████████| 96/96 [00:02<00:00, 32.27it/s, loss=3.3136]\n",
      "Validation Epoch 77: 100%|██████████| 24/24 [00:00<00:00, 28.52it/s, loss=3.9964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 77:\n",
      "Average Train Loss: 3.6306\n",
      "Average Val Loss: 3.6760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 78: 100%|██████████| 96/96 [00:02<00:00, 32.56it/s, loss=3.4387]\n",
      "Validation Epoch 78: 100%|██████████| 24/24 [00:00<00:00, 28.23it/s, loss=3.7163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 78:\n",
      "Average Train Loss: 3.6543\n",
      "Average Val Loss: 3.6168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 79: 100%|██████████| 96/96 [00:02<00:00, 33.51it/s, loss=3.3433]\n",
      "Validation Epoch 79: 100%|██████████| 24/24 [00:00<00:00, 27.59it/s, loss=3.9958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 79:\n",
      "Average Train Loss: 3.6865\n",
      "Average Val Loss: 3.6733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 80: 100%|██████████| 96/96 [00:02<00:00, 32.21it/s, loss=3.2543]\n",
      "Validation Epoch 80: 100%|██████████| 24/24 [00:00<00:00, 27.90it/s, loss=3.5401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80:\n",
      "Average Train Loss: 3.6239\n",
      "Average Val Loss: 3.5407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 81: 100%|██████████| 96/96 [00:02<00:00, 32.31it/s, loss=3.4039]\n",
      "Validation Epoch 81: 100%|██████████| 24/24 [00:00<00:00, 27.48it/s, loss=3.4988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 81:\n",
      "Average Train Loss: 3.6290\n",
      "Average Val Loss: 3.6341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 82: 100%|██████████| 96/96 [00:02<00:00, 33.37it/s, loss=3.7970]\n",
      "Validation Epoch 82: 100%|██████████| 24/24 [00:00<00:00, 28.33it/s, loss=3.7539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 82:\n",
      "Average Train Loss: 3.6398\n",
      "Average Val Loss: 3.6549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 83: 100%|██████████| 96/96 [00:03<00:00, 31.94it/s, loss=3.6913]\n",
      "Validation Epoch 83: 100%|██████████| 24/24 [00:00<00:00, 28.38it/s, loss=3.5833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 83:\n",
      "Average Train Loss: 3.6407\n",
      "Average Val Loss: 3.6013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 84: 100%|██████████| 96/96 [00:03<00:00, 31.81it/s, loss=3.3534]\n",
      "Validation Epoch 84: 100%|██████████| 24/24 [00:00<00:00, 27.82it/s, loss=3.9553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 84:\n",
      "Average Train Loss: 3.6708\n",
      "Average Val Loss: 3.6441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 85: 100%|██████████| 96/96 [00:03<00:00, 31.86it/s, loss=3.9950]\n",
      "Validation Epoch 85: 100%|██████████| 24/24 [00:00<00:00, 27.95it/s, loss=3.8746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 85:\n",
      "Average Train Loss: 3.6461\n",
      "Average Val Loss: 3.5827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 86: 100%|██████████| 96/96 [00:02<00:00, 36.92it/s, loss=3.5485]\n",
      "Validation Epoch 86: 100%|██████████| 24/24 [00:00<00:00, 28.11it/s, loss=3.5011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 86:\n",
      "Average Train Loss: 3.6417\n",
      "Average Val Loss: 3.6332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 87: 100%|██████████| 96/96 [00:03<00:00, 31.83it/s, loss=3.8463]\n",
      "Validation Epoch 87: 100%|██████████| 24/24 [00:00<00:00, 28.07it/s, loss=3.6075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 87:\n",
      "Average Train Loss: 3.6568\n",
      "Average Val Loss: 3.6433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 88: 100%|██████████| 96/96 [00:02<00:00, 32.10it/s, loss=3.9680]\n",
      "Validation Epoch 88: 100%|██████████| 24/24 [00:00<00:00, 30.51it/s, loss=3.6105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 88:\n",
      "Average Train Loss: 3.6772\n",
      "Average Val Loss: 3.6456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 89: 100%|██████████| 96/96 [00:02<00:00, 32.27it/s, loss=4.2282]\n",
      "Validation Epoch 89: 100%|██████████| 24/24 [00:00<00:00, 27.46it/s, loss=3.7001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 89:\n",
      "Average Train Loss: 3.6514\n",
      "Average Val Loss: 3.6314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 90: 100%|██████████| 96/96 [00:02<00:00, 36.73it/s, loss=4.0527]\n",
      "Validation Epoch 90: 100%|██████████| 24/24 [00:00<00:00, 28.36it/s, loss=3.7107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90:\n",
      "Average Train Loss: 3.6678\n",
      "Average Val Loss: 3.6060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 91: 100%|██████████| 96/96 [00:03<00:00, 31.88it/s, loss=3.8543]\n",
      "Validation Epoch 91: 100%|██████████| 24/24 [00:00<00:00, 27.64it/s, loss=3.5607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 91:\n",
      "Average Train Loss: 3.6308\n",
      "Average Val Loss: 3.6176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 92: 100%|██████████| 96/96 [00:03<00:00, 30.85it/s, loss=3.6712]\n",
      "Validation Epoch 92: 100%|██████████| 24/24 [00:00<00:00, 27.81it/s, loss=3.5405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 92:\n",
      "Average Train Loss: 3.6331\n",
      "Average Val Loss: 3.6602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 93: 100%|██████████| 96/96 [00:03<00:00, 31.32it/s, loss=3.5905]\n",
      "Validation Epoch 93: 100%|██████████| 24/24 [00:00<00:00, 28.06it/s, loss=3.6564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 93:\n",
      "Average Train Loss: 3.6378\n",
      "Average Val Loss: 3.6559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 94: 100%|██████████| 96/96 [00:03<00:00, 31.83it/s, loss=3.8305]\n",
      "Validation Epoch 94: 100%|██████████| 24/24 [00:00<00:00, 27.90it/s, loss=3.7487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 94:\n",
      "Average Train Loss: 3.6435\n",
      "Average Val Loss: 3.6171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 95: 100%|██████████| 96/96 [00:03<00:00, 30.78it/s, loss=3.8776]\n",
      "Validation Epoch 95: 100%|██████████| 24/24 [00:00<00:00, 27.50it/s, loss=3.7098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 95:\n",
      "Average Train Loss: 3.6551\n",
      "Average Val Loss: 3.7013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 96: 100%|██████████| 96/96 [00:03<00:00, 30.92it/s, loss=3.3968]\n",
      "Validation Epoch 96: 100%|██████████| 24/24 [00:00<00:00, 27.90it/s, loss=3.5005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 96:\n",
      "Average Train Loss: 3.6869\n",
      "Average Val Loss: 3.5937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 97: 100%|██████████| 96/96 [00:02<00:00, 34.37it/s, loss=3.5994]\n",
      "Validation Epoch 97: 100%|██████████| 24/24 [00:00<00:00, 27.17it/s, loss=3.7008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 97:\n",
      "Average Train Loss: 3.6209\n",
      "Average Val Loss: 3.6063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 98: 100%|██████████| 96/96 [00:03<00:00, 31.00it/s, loss=3.8332]\n",
      "Validation Epoch 98: 100%|██████████| 24/24 [00:00<00:00, 27.48it/s, loss=3.8600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 98:\n",
      "Average Train Loss: 3.6639\n",
      "Average Val Loss: 3.6811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 99: 100%|██████████| 96/96 [00:03<00:00, 30.99it/s, loss=3.4038]\n",
      "Validation Epoch 99: 100%|██████████| 24/24 [00:00<00:00, 27.75it/s, loss=3.5705]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 99:\n",
      "Average Train Loss: 3.6720\n",
      "Average Val Loss: 3.6369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 100: 100%|██████████| 96/96 [00:02<00:00, 35.39it/s, loss=3.5759]\n",
      "Validation Epoch 100: 100%|██████████| 24/24 [00:00<00:00, 27.91it/s, loss=3.7881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100:\n",
      "Average Train Loss: 3.6401\n",
      "Average Val Loss: 3.6619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 101: 100%|██████████| 96/96 [00:03<00:00, 30.97it/s, loss=3.6163]\n",
      "Validation Epoch 101: 100%|██████████| 24/24 [00:00<00:00, 27.89it/s, loss=3.5538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 101:\n",
      "Average Train Loss: 3.6481\n",
      "Average Val Loss: 3.6048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 102: 100%|██████████| 96/96 [00:03<00:00, 30.96it/s, loss=3.4462]\n",
      "Validation Epoch 102: 100%|██████████| 24/24 [00:00<00:00, 27.51it/s, loss=3.5728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 102:\n",
      "Average Train Loss: 3.6476\n",
      "Average Val Loss: 3.6069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 103: 100%|██████████| 96/96 [00:03<00:00, 31.98it/s, loss=4.1694]\n",
      "Validation Epoch 103: 100%|██████████| 24/24 [00:00<00:00, 27.91it/s, loss=3.3516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 103:\n",
      "Average Train Loss: 3.6588\n",
      "Average Val Loss: 3.5395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 104: 100%|██████████| 96/96 [00:03<00:00, 31.16it/s, loss=3.2135]\n",
      "Validation Epoch 104: 100%|██████████| 24/24 [00:00<00:00, 27.54it/s, loss=3.6734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 104:\n",
      "Average Train Loss: 3.6438\n",
      "Average Val Loss: 3.6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 105: 100%|██████████| 96/96 [00:03<00:00, 30.99it/s, loss=2.9612]\n",
      "Validation Epoch 105: 100%|██████████| 24/24 [00:00<00:00, 27.90it/s, loss=3.5997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 105:\n",
      "Average Train Loss: 3.6572\n",
      "Average Val Loss: 3.6361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 106: 100%|██████████| 96/96 [00:03<00:00, 30.94it/s, loss=3.4446]\n",
      "Validation Epoch 106: 100%|██████████| 24/24 [00:00<00:00, 28.10it/s, loss=3.4187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 106:\n",
      "Average Train Loss: 3.6600\n",
      "Average Val Loss: 3.6547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 107: 100%|██████████| 96/96 [00:02<00:00, 40.02it/s, loss=3.6379]\n",
      "Validation Epoch 107: 100%|██████████| 24/24 [00:00<00:00, 65.99it/s, loss=3.7190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 107:\n",
      "Average Train Loss: 3.6433\n",
      "Average Val Loss: 3.5981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 108: 100%|██████████| 96/96 [00:02<00:00, 42.20it/s, loss=3.3756]\n",
      "Validation Epoch 108: 100%|██████████| 24/24 [00:00<00:00, 66.27it/s, loss=3.5472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 108:\n",
      "Average Train Loss: 3.6425\n",
      "Average Val Loss: 3.6659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 109: 100%|██████████| 96/96 [00:02<00:00, 42.22it/s, loss=3.6659]\n",
      "Validation Epoch 109: 100%|██████████| 24/24 [00:00<00:00, 65.88it/s, loss=3.7765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 109:\n",
      "Average Train Loss: 3.6563\n",
      "Average Val Loss: 3.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 110: 100%|██████████| 96/96 [00:02<00:00, 34.68it/s, loss=3.7406]\n",
      "Validation Epoch 110: 100%|██████████| 24/24 [00:00<00:00, 30.18it/s, loss=3.8967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 110:\n",
      "Average Train Loss: 3.6335\n",
      "Average Val Loss: 3.6460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 111: 100%|██████████| 96/96 [00:02<00:00, 34.10it/s, loss=3.6252]\n",
      "Validation Epoch 111: 100%|██████████| 24/24 [00:00<00:00, 29.42it/s, loss=3.4235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 111:\n",
      "Average Train Loss: 3.6532\n",
      "Average Val Loss: 3.6318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 112:  98%|█████████▊| 94/96 [00:02<00:00, 34.57it/s, loss=3.5247]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 141\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, train_loader, test_loader, optimizer, num_epochs, device, use_lr_scheduling)\u001b[0m\n\u001b[1;32m    135\u001b[0m     scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(\n\u001b[1;32m    136\u001b[0m         optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     avg_train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     log_metrics({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain/epoch_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: avg_train_loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch})\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# Validation phase (every 5 epochs)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 263\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, optimizer, device, epoch)\u001b[0m\n\u001b[1;32m    260\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    261\u001b[0m mask \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 263\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m    265\u001b[0m train_bar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m})\n",
      "Cell \u001b[0;32mIn[5], line 246\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, tokens, mask, optimizer, device)\u001b[0m\n\u001b[1;32m    244\u001b[0m     model\u001b[38;5;241m.\u001b[39mcollect_time_statistics(t, loss\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[1;32m    245\u001b[0m     model\u001b[38;5;241m.\u001b[39mupdate_time_warping_batch()  \u001b[38;5;66;03m# New method we'll add\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/matlas/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/matlas/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/matlas/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# Start training\n",
    "train_and_validate(model, train_loader, test_loader, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'model_args': {\n",
    "        'vocab_size': vocab_size,\n",
    "        'embed_dim': embed_dim,\n",
    "        'num_layers': num_layers,\n",
    "        'num_heads': num_heads,\n",
    "        'dim_feedforward': dim_feedforward,\n",
    "        'num_fourier_features': num_fourier_features\n",
    "    }\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'model_checkpoint_3.58pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_arch import CategoricalScoreDiffusion\n",
    "\n",
    "checkpoint = torch.load('model_checkpoint_2.65.pt')\n",
    "model = CategoricalScoreDiffusion(**checkpoint['model_args'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Access the learning rate\n",
    "# Get the optimizer state dict\n",
    "optimizer_state = checkpoint['optimizer_state_dict']\n",
    "learning_rate = optimizer_state['param_groups'][0]['lr']\n",
    "print(f\"Learning rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    start = time.perf_counter()\n",
    "    yield\n",
    "    end = time.perf_counter()\n",
    "    print(f\"{name}: {(end - start)*1000:.2f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralink",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
